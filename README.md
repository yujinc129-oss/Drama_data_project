📺 한국 드라마 평점 예측 모델 개발 프로젝트
1. 프로젝트 개요
  본 프로젝트는 Kaggle의 'MyDramaList' 데이터를 기반으로, 한국 드라마와 출연 배우의 다양한 정보를 활용하여 평점을 예측하는 회귀 모델을 개발하는 것을 목표로 합니다. 데이터 정제부터 특성 공학, 다양한 머신러닝 모델 비교, 하이퍼파라미터 튜닝에 이르는 모델 개발의 전 과정을 체계적으로 담았습니다.

2. 데이터 정제 및 전처리 (Data Cleansing & Preprocessing)
  데이터 소스: Kaggle의 MyDramaList 데이터셋을 활용하여 드라마, 배우, 평점 정보를 수집했습니다.
  
  데이터 병합: 원활한 데이터 통합을 위해 드라마 제목을 소문자로 변환하고 공백을 제거하는 등 텍스트 정규화를 진행한 후, 드라마명을 기준으로 각 데이터를 병합했습니다.
  
  날짜 데이터 처리: pd.to_datetime을 사용하여 다양한 형식의 날짜 데이터를 표준 YYYY-MM-DD 형식으로 통일했습니다.
  
  평점 정규화: score(평점)와 scored by(평가 인원) 컬럼을 활용하여 **가중 평점(Weighted Rating)**을 계산했습니다. 이를 통해 평가 인원이 적은 드라마의 평점은 전체 평균에 가깝게 보정하고, 평가 인원이 많은 드라마의 평점은 신뢰도를 높여 점수의 객관성을 확보했습니다.
  
  컬럼 정비: 직관적인 분석을 위해 각 데이터셋의 컬럼명을 일관성 있게 변경했습니다.

  결측값제거 : 

3. 특성 공학 (Feature Engineering)
  모델의 예측 성능을 극대화하기 위해 기존 변수를 조합하여 다음과 같은 의미 있는 파생변수를 생성했습니다.
  
  촬영 당시 나이: 드라마 방영 연도 - 배우 출생 연도를 계산하여 배우의 연령대가 갖는 영향을 반영했습니다.
  
  메인 역할 비율: 배우의 전체 필모그래피 중 주연을 맡은 비율을 계산하여 배우의 인지도와 스타성을 수치화했습니다.
  
  플랫폼 등급 (Tier): 방송사 및 OTT 플랫폼의 영향력을 1~3등급으로 나누어, 플랫폼이 갖는 파워를 변수로 활용했습니다.
  
  방영 분기: 방영 시작 월을 4분기로 그룹화하여 드라마의 계절적 요인을 추가했습니다.

4. 인코딩 (Encoding)
  범주형 변수를 모델이 학습할 수 있도록 다음과 같은 인코딩 기법을 적용했습니다.
  
  원-핫 인코딩: role, gender와 같이 단일 값을 갖는 명목형 변수를 처리했습니다.
  
  다중 값 인코딩: genres, network, day처럼 하나의 데이터가 리스트 형태로 여러 값을 갖는 경우, MultiLabelBinarizer 또는 CountVectorizer(binary=True)를 활용하여 각 값을 개별 변수로 분리했습니다.

모델링 및 평가 (Modeling & Evaluation)

Linear Regression: 베이스라인 모델로 성능을 측정했으나, 과소적합 문제를 확인했습니다.

Random Forest: 비선형 관계 학습에 강점을 보여 성능이 크게 향상되었으나, 과대적합(Overfitting) 문제가 발생했습니다.

XGBoost: 과대적합 제어에 더 강력한 부스팅 모델을 최종 모델로 선택했습니다.

평가 지표: 모델의 예측 성능은 R² Score로, 오차의 크기는 RMSE, MAE로 평가했습니다.

하이퍼파라미터 튜닝 (Hyperparameter Tuning)

RandomizedSearchCV를 사용해 넓은 범위에서 최적 파라미터 후보를 빠르게 탐색했습니다.

GridSearchCV를 활용하여 유망한 후보군 주변을 촘촘하게 탐색하며 최종 파라미터를 결정했습니다.

튜닝의 주된 목표는 과대적합을 제어하여 Train-Test 스코어 격차를 줄이고 모델의 일반화 성능을 높이는 것이었습니다.

XGBoost 모델의 과대적합 제어를 위해 Early Stopping(조기 종료) 기법을 활용했습니다.

3. 결론
최종 모델: XGBoost Regressor

최종 Test R² Score: 약 0.70

주요 발견점:

단순 선형 모델보다 복잡한 비선형 관계를 학습할 수 있는 트리 기반 앙상블 모델이 훨씬 효과적이었습니다.

플랫폼 등급, 메인 역할 비율 등 새롭게 생성한 파생변수들이 모델 성능 향상에 크게 기여했습니다.

과대적합 제어를 위한 하이퍼파라미터 튜닝, 특히 XGBoost의 learning_rate 조절과 Early Stopping이 일반화 성능 확보에 핵심적인 역할을 했습니다.
